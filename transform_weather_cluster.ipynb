{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from __future__ import absolute_import\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'uber-fair'\n",
    "BUCKET = 'gs://uber-fair-beam-bucket'\n",
    "DIR_PATH_IN = BUCKET + '/input/' \n",
    "DIR_PATH = BUCKET + '/output/' + datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S') + '/'\n",
    "           \n",
    "class CastAsDateTime(beam.DoFn):\n",
    "  def process(self, element):\n",
    "    import datetime\n",
    "    wData = element\n",
    "    weatherDate = str(datetime.datetime.fromtimestamp(wData[\"time_stamp\"]).strftime('%Y-%m-%d'))\n",
    "    wData['time_stamp'] = weatherDate\n",
    "    return [wData]\n",
    "         \n",
    "\n",
    "# run pipeline on Dataflow \n",
    "options = {\n",
    "    'runner': 'DataflowRunner',\n",
    "    'job_name': 'transform-weather-date-5',\n",
    "    'project': PROJECT_ID,\n",
    "    'temp_location': BUCKET + '/temp',\n",
    "    'staging_location': BUCKET + '/staging',\n",
    "    'machine_type': 'n1-standard-4', # machine types listed here: https://cloud.google.com/compute/docs/machine-types\n",
    "    'num_workers': 10\n",
    "}\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "\n",
    "p = beam.Pipeline('DataflowRunner', options=opts)\n",
    "\n",
    "sql = 'SELECT * FROM weather_modeled.weather'\n",
    "bq_source = beam.io.BigQuerySource(query=sql, use_standard_sql=True)\n",
    "\n",
    "query_results = p | 'Read from BigQuery' >> beam.io.Read(bq_source)\n",
    "\n",
    "# write PCollection to log file\n",
    "query_results | 'Write log 1' >> WriteToText(DIR_PATH + 'query_results.txt')\n",
    "\n",
    "# remove duplicate student records\n",
    "formatted_date_pcoll = query_results | 'ParDo for Date' >> beam.ParDo(CastAsDateTime())\n",
    "\n",
    "# write PCollection to log file\n",
    "formatted_date_pcoll | 'Write log 2' >> WriteToText(DIR_PATH + 'formatted_date_pcoll.txt')\n",
    "\n",
    "dataset_id = 'weather_modeled'\n",
    "table_id = 'weather_DF'\n",
    "schema_id = 'temp:FLOAT,location:STRING, clouds:FLOAT,pressure:FLOAT,rain:FLOAT,time_stamp:DATE,humidity:FLOAT,wind:FLOAT,id:STRING'\n",
    "\n",
    "# write PCollection to new BQ table\n",
    "formatted_date_pcoll | 'Write BQ table' >> beam.io.WriteToBigQuery(dataset=dataset_id, \n",
    "                                                table=table_id, \n",
    "                                                schema=schema_id,\n",
    "                                                project=PROJECT_ID,\n",
    "                                                create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "                                                write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "                                                batch_size=int(100))\n",
    "result = p.run()\n",
    "result.wait_until_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
